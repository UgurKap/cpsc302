{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 302: Assignment 4\n",
    "## Nicholas Hu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "*False.* Consider the matrix \n",
    "\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 2 \n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Its inverse is\n",
    "\n",
    "$$\n",
    "A^{-1} =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & \\tfrac{1}{2} \n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "However, $\\lVert A^{-1} \\rVert_1 = 1$ whereas $\\lVert A \\rVert_1^{-1} = 2^{-1} = \\tfrac{1}{2}$; clearly $1 \\neq \\tfrac{1}{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "#### (a)\n",
    "\n",
    "It suffices to show that\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "c & s \\\\\n",
    "-s & c\n",
    "\\end{bmatrix}^\\top\n",
    "\\begin{bmatrix}\n",
    "c & s \\\\\n",
    "-s & c\n",
    "\\end{bmatrix} =\n",
    "I.\n",
    "$$\n",
    "\n",
    "Indeed,\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "c & s \\\\\n",
    "-s & c\n",
    "\\end{bmatrix}^\\top\n",
    "\\begin{bmatrix}\n",
    "c & s \\\\\n",
    "-s & c\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "c & -s \\\\\n",
    "s & c\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "c & s \\\\\n",
    "-s & c\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "c^2 + s^2 & cs - sc \\\\\n",
    "sc - cs & s^2 + c^2\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix} =\n",
    "I,\n",
    "$$\n",
    "\n",
    "so the given matrix is indeed orthogonal as its transpose is its inverse.\n",
    "\n",
    "#### (b)\n",
    "\n",
    "**i.** Let $Q = \\begin{bmatrix}\n",
    "c & s \\\\\n",
    "-s & c\n",
    "\\end{bmatrix}$. We showed in part (a) that $Q$ is orthogonal when $c^2 + s^2 = 1$. Hence $\\lVert Q \\vec{x} \\rVert_2 = \\lVert \\vec{x} \\rVert_2$ (Ascher and Greif, p. 80). Thus\n",
    "\n",
    "\\begin{align*}\n",
    "\\left\\lVert\n",
    "Q\n",
    "\\begin{bmatrix}\n",
    "a_1 \\\\ a_2\n",
    "\\end{bmatrix}\n",
    "\\right\\rVert_2 &=\n",
    "\\left\\lVert\n",
    "\\begin{bmatrix}\n",
    "\\alpha \\\\ 0\n",
    "\\end{bmatrix}\n",
    "\\right\\rVert_2 \\\\\n",
    "\\implies\n",
    "\\left\\lVert\n",
    "\\begin{bmatrix}\n",
    "a_1 \\\\ a_2\n",
    "\\end{bmatrix}\n",
    "\\right\\rVert_2 &=\n",
    "\\left\\lVert\n",
    "\\begin{bmatrix}\n",
    "\\alpha \\\\ 0\n",
    "\\end{bmatrix}\n",
    "\\right\\rVert_2\n",
    "\\\\ \n",
    "\\implies \\alpha &= \\sqrt{a_1^2 + a_2^2} \\,.\n",
    "\\end{align*}\n",
    "\n",
    "**ii.** The given matrix equation can be rewritten as\n",
    "\n",
    "\\begin{align*}\n",
    "\\begin{bmatrix}\n",
    "a_1 & a_2 \\\\\n",
    "a_2 & -a_1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "c \\\\ s\n",
    "\\end{bmatrix} &=\n",
    "\\begin{bmatrix}\n",
    "\\alpha \\\\ 0\n",
    "\\end{bmatrix} \\\\\n",
    "\\implies\n",
    "\\begin{bmatrix}\n",
    "c \\\\ s\n",
    "\\end{bmatrix} &=\n",
    "\\frac{-1}{a_1^2 + a_2^2}\n",
    "\\begin{bmatrix}\n",
    "-a_1 & -a_2 \\\\\n",
    "-a_2 & a_1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\alpha \\\\ 0\n",
    "\\end{bmatrix} =\n",
    "\\frac{-1}{\\alpha^2}\n",
    "\\begin{bmatrix}\n",
    "-a_1 \\alpha \\\\\n",
    "-a_2 \\alpha\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "\\tfrac{a_1}{\\alpha} \\\\\n",
    "\\tfrac{a_2}{\\alpha}\n",
    "\\end{bmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "Hence we can select $c = \\frac{a_1}{\\alpha}$ and $s = \\frac{a_2}{\\alpha}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "#### (a)\n",
    "\n",
    "Let $Q$ be an orthogonal matrix and suppose $\\lambda$ is an eigenvalue of $Q$ with eigenvector $\\vec{x}$. Then \n",
    "\n",
    "\\begin{align*}\n",
    "\\lVert \\vec{x} \\rVert_2 &= \\lVert Q \\vec{x} \\rVert_2 && \\text{by orthogonality of $Q$} \\\\\n",
    "&= \\lVert \\lambda \\vec{x} \\rVert_2 && \\text{by hypothesis} \\\\\n",
    "&= \\lvert \\lambda \\rvert \\lVert \\vec{x} \\rVert_2 && \\text{by absolute homogeneity}\n",
    "\\end{align*}\n",
    "\n",
    "which implies that $\\lvert \\lambda \\rvert = 1$ since by definition $\\vec{x} \\neq \\vec{0}$.\n",
    "\n",
    "#### (b)\n",
    "\n",
    "Let $P$ be a projection and suppose $\\lambda$ is an eigenvalue of $P$ with eigenvector $\\vec{x}$. Then \n",
    "\n",
    "\\begin{align*}\n",
    "\\lambda \\vec{x} &= P \\vec{x} && \\text{by hypothesis} \\\\\n",
    "&= P^2 \\vec{x} && \\text{since $P$ is a projection} \\\\\n",
    "&= P (P \\vec{x}) \\\\\n",
    "&= \\lambda P \\vec{x} && \\text{by hypothesis} \\\\\n",
    "&= \\lambda^2 \\vec{x} && \\text{by hypothesis}\n",
    "\\end{align*}\n",
    "\n",
    "which implies that $\\lambda = \\lambda^2$. Therefore $\\lambda$ is either $0$ or $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "The singular values of a matrix $A$ are the square roots of the eigenvalues of $A^\\top A$. \n",
    "\n",
    "Since we are given that $A$ is symmetric, $A^\\top A = A^2$. Now let $\\vec{x}_i$ be an eigenvector of eigenvalue $\\lambda_i$. Then $A \\vec{x}_i = \\lambda_i \\vec{x}_i \\implies A^2 \\vec{x}_i = \\lambda_i A \\vec{x}_i = \\lambda^2 \\vec{x}_i$. Hence the eigenvalues of $A^\\top A$ are $\\lambda_i^2$ for $i = 1, \\dots, n$. It follows that the singular values of $A$ are $\\sigma_i = \\sqrt{\\lambda_i^2} = \\lvert \\lambda_i \\rvert$, $i = 1, \\dots, n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "#### (1)\n",
    "\n",
    "For $A \\in \\mathcal{M}_{m \\times n}(\\mathbb{R})$, let $\\mathrm{vec}(A) := [a_{11}\\ a_{12}\\ \\cdots\\ a_{1n}\\ a_{21}\\ \\cdots\\ a_{2n}\\ \\cdots\\ a_{m1}\\ \\cdots\\ a_{mn}]$. Clearly $\\mathrm{vec}$ defines an isomorphism between $\\mathcal{M}_{m \\times n}(\\mathbb{R})$ and $\\mathbb{R}^{mn}$. It is also clear that $\\lVert A \\rVert_F = \\lVert \\mathrm{vec}(A) \\rVert_2$. Thus it suffices to verify that the $\\ell^2$-norm is a norm (on $\\mathbb{R}^{mn}$).\n",
    "\n",
    "Recall that $\\lVert \\vec{x} \\rVert_2 = \\sqrt{\\sum_{i=1}^{mn} x_i^2}$ for $\\vec{x} \\in \\mathbb{R}^{mn}$ (henceforth we omit the limits of the summation symbol for readability).\n",
    "\n",
    "If $\\lVert \\vec{x} \\rVert_2 = 0$, then $\\sqrt{\\sum x_i^2} = 0 \\implies \\sum x_i^2 = 0 \\implies \\forall i\\  x_i = 0 \\implies \\vec{x} = \\vec{0}$. Hence we have **(i)** $\\lVert \\vec{x} \\rVert_2 = 0 \\implies \\vec{x} = \\vec{0}$.\n",
    "\n",
    "For $\\alpha \\in \\mathbb{R}$, we also have **(ii)** $\\lVert \\alpha \\vec{x} \\rVert_2 = \\sqrt{\\sum (\\alpha x_i)^2} = \\sqrt{\\alpha^2 \\sum x_i^2} = \\lvert \\alpha \\rvert \\sqrt{\\sum x_i^2} = \\lvert \\alpha \\rvert \\lVert \\vec{x} \\rVert_2$.\n",
    "\n",
    "Finally, $\\lVert \\vec{x} + \\vec{y} \\rVert_2^2 = (\\vec{x} + \\vec{y}) \\cdot (\\vec{x} + \\vec{y}) = \\lVert \\vec{x} \\rVert_2^2 + 2 (\\vec{x} \\cdot \\vec{y}) + \\lVert \\vec{y} \\rVert_2^2$. By the Cauchy-Schwarz inequality, $\\lvert \\vec{x} \\cdot \\vec{y} \\rvert \\leq \\lVert \\vec{x} \\rVert_2 \\lVert \\vec{y} \\rVert_2$, we have $\\lVert \\vec{x} + \\vec{y} \\rVert_2^2 \\leq \\lVert \\vec{x} \\rVert_2^2 + 2 \\lVert \\vec{x} \\rVert_2 \\lVert \\vec{y} \\rVert_2 + \\lVert \\vec{y} \\rVert_2^2 = (\\lVert \\vec{x} \\rVert_2 + \\lVert \\vec{y} \\rVert_2)^2$. Taking square roots yields the triangle inequality **(iii)** $\\lVert \\vec{x} + \\vec{y} \\rVert_2 \\leq \\lVert \\vec{x} \\rVert_2 + \\lVert \\vec{y} \\rVert_2$.\n",
    "\n",
    "Note that the nonnegativity of the norm follows from the above properties; that $\\lVert \\vec{x} \\rVert_2 = 0 \\Longleftrightarrow \\vec{x} = \\vec{0}$ follows from **(i)** and **(ii)**.\n",
    "\n",
    "Since the $\\ell^2$-norm is indeed a norm on $\\mathbb{R}^{mn}$, it follows that the Frobenius norm is a norm on $\\mathcal{M}_{m \\times n}(\\mathbb{R})$.\n",
    "\n",
    "#### (2)\n",
    "\n",
    "Let $a_{ij}, a'_{ij}, c_{ij}$ denote the $(i, j)$-entries of $A$, $A^\\top$, and $C = A^\\top A$, respectively. Then\n",
    "\n",
    "$$\n",
    "c_{kk} = \\sum_{l=1}^m a'_{kl} a_{lk} = \\sum_{l=1}^m a_{lk} a_{lk} \\implies \\mathrm{tr}(C) = \\sum_{k=1}^n c_{kk} = \\sum_{k=1}^n \\sum_{l=1}^m a_{lk}^2 = \\sum_{l=1}^m \\sum_{k=1}^n a_{lk}^2 = \\lVert A \\rVert^2_F \\,.\n",
    "$$\n",
    "\n",
    "as claimed.\n",
    "\n",
    "#### (3)\n",
    "\n",
    "Let $U \\Sigma V^\\top$ be the singular value decomposition of $A$. Then\n",
    "\n",
    "\\begin{align*}\n",
    "\\lVert A \\rVert_F &= \\sqrt{\\mathrm{tr}(A^\\top A)} \\\\\n",
    "&= \\sqrt{\\mathrm{tr}(V \\Sigma^\\top U^\\top U \\Sigma V^\\top)} && \\text{since $(AB)^\\top = B^\\top A^\\top$ and $(A^\\top)^\\top = A$} \\\\\n",
    "&= \\sqrt{\\mathrm{tr}(V \\Sigma^\\top \\Sigma V^\\top)} && \\text{since $U$ is orthogonal} \\\\\n",
    "&= \\sqrt{\\mathrm{tr}(V^\\top V \\Sigma^\\top \\Sigma)} && \\text{since $\\mathrm{tr}(AB) = \\mathrm{tr}(BA)$} \\\\\n",
    "&= \\sqrt{\\mathrm{tr}(\\Sigma^\\top \\Sigma)} && \\text{since $V$ is orthogonal} \\\\\n",
    "&= \\sqrt{\\sum\\nolimits_{k=1}^n \\sigma_k^2}.\n",
    "\\end{align*}\n",
    "\n",
    "But $\\mathrm{rank}(A) \\leq \\min \\{m, n\\}$, so if $m < n$, the singular values $\\sigma_k$ are zero for all $k \\geq m$ (assuming that they are given in decreasing order). (If $m \\geq n$, the given expression is exactly the one above.) Hence $\\lVert A \\rVert_F = \\sqrt{\\sum\\nolimits_{k=1}^{\\min \\{m, n\\}} \\sigma_k^2}$ as claimed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
